def create_prompt_template():
    template = """
    You are a helpful AI assistant for creating new datasets. 
    Your task is to generate new observations based on the provided examples and schema.
    The new observations should be similar to the examples.

    **Numeric Data**: 
    - Ensure that the numeric values in the generated data follow the same distributions as provided in the schema.
    - For each numeric column, generate values that adhere to the following properties from the schema: mean, standard deviation, minimum, maximum, and percentiles (25th, 50th, and 75th).
    - The generated values should fall within the range of the original data (min and max) and match the distribution described by the schema.

    **Categorical Data**: 
    - Ensure that the frequency distribution of categorical values matches the distribution provided in the schema.
    - The proportion of each category (e.g., Male/Female) should be preserved based on the frequencies in the schema.

    The formatting of the new observations should match the formatting of the examples: 
    column 1: value 1, column 2: value 2...column n: value n.

    **Examples**:
    {examples}

    **Schema**:
    {schema}
    
    **Count**: Generate {count} new observations.

    Only return the new observations, do not include any explanation.
    """
    
    prompt = PromptTemplate(
        template=template,
        input_variables=["examples", "schema", "count"]
    )

    return prompt

import pandas as pd
import numpy as np

# Function to generate schema, now handling numeric, categorical, and free-form text
def generate_schema(df):
    schema = {}

    # For numeric columns
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    for col in numeric_columns:
        col_stats = {
            "data_type": "numeric",
            "mean": df[col].mean(),
            "std": df[col].std(),
            "min": df[col].min(),
            "max": df[col].max(),
            "25th_percentile": df[col].quantile(0.25),
            "50th_percentile": df[col].quantile(0.50),  # Median
            "75th_percentile": df[col].quantile(0.75)
        }
        schema[col] = col_stats

    # For categorical columns
    categorical_columns = df.select_dtypes(include=['object', 'category']).columns
    for col in categorical_columns:
        if df[col].nunique() < 50:  # Treat columns with a small number of unique values as categorical
            value_counts = df[col].value_counts(normalize=True)
            col_stats = {
                "data_type": "categorical",
                "distribution": value_counts.to_dict()
            }
            schema[col] = col_stats

    # For free-form text columns (treated as 'object' but with high uniqueness)
    text_columns = df.select_dtypes(include=['object']).columns
    for col in text_columns:
        if df[col].nunique() > 50:  # Assume high uniqueness indicates free-form text
            text_lengths = df[col].dropna().apply(len)  # Calculate the length of each text entry
            col_stats = {
                "data_type": "text",
                "average_length": text_lengths.mean(),
                "min_length": text_lengths.min(),
                "max_length": text_lengths.max(),
                "sample_text": df[col].dropna().sample(3).tolist()  # Provide a few examples
            }
            schema[col] = col_stats

    return schema

# Example Usage:
file_path = "tips.csv"
csv_data = pd.read_csv(file_path)

# Generate the schema for numeric, categorical, and text columns
schema = generate_schema(csv_data)

# Convert to JSON format for easy reading or passing to the model
import json
schema_json = json.dumps(schema, indent=4)
print(schema_json)
